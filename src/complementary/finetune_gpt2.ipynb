{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2367e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Plancha\\Desktop\\AML-homework\\.pixi\\envs\\gpu\\Lib\\site-packages\\transformers\\utils\\hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pyprojroot import here\n",
    "os.environ['TRANSFORMERS_CACHE'] = str(here(\"cache/transformers\"))\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model_name = \"openai-community/gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59f1b192",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The future of artificial intelligence is still uncertain, but we do not yet have a clear roadmap for the future of AI. In any case, there are plenty of opportunities for our society to continue to innovate and grow, and our future will shape our future.\n",
      "\n",
      "I hope that you will join me in congratulating the new CEO of IBM, Dr. Jeff Bezos, and the amazing staff at IBM for taking the time to speak with us. Thank you for letting us share your thoughts and ideas on the future of AI and the\n"
     ]
    }
   ],
   "source": [
    "# test one example\n",
    "model.eval()\n",
    "# Add padding token if not already present\n",
    "tokenizer.add_special_tokens({'pad_token': '<|pad|>'})\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Generate text\n",
    "prompt = \"The future of artificial intelligence is\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Generate with different parameters\n",
    "with torch.no_grad():\n",
    "  outputs = model.generate(\n",
    "    inputs.input_ids,\n",
    "    max_new_tokens=100,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    do_sample=True,\n",
    "    temperature=0.7\n",
    "  )\n",
    "\n",
    "# Decode and display\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4084d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>directions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No-Bake Nut Cookies</td>\n",
       "      <td>[In a heavy 2-quart saucepan, mix brown sugar,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jewell Ball'S Chicken</td>\n",
       "      <td>[Place chipped beef on bottom of baking dish.,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Creamy Corn</td>\n",
       "      <td>[In a slow cooker, combine all ingredients. Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chicken Funny</td>\n",
       "      <td>[Boil and debone chicken., Put bite size piece...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reeses Cups(Candy)</td>\n",
       "      <td>[Combine first four ingredients and press in 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Heath Bar Pie</td>\n",
       "      <td>[Mix chopped Heath bars with whipped topping a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Victorian Baked French Toast</td>\n",
       "      <td>[Cook brown sugar, butter and corn syrup in sm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Quick Swedish Meatballs</td>\n",
       "      <td>[Combine meat, bread crumbs, cheese, soup mix,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Irish Stew(Microwave)</td>\n",
       "      <td>[In 4-quart casserole, combine lamb, 1 1/4 cup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Peach Salad</td>\n",
       "      <td>[Mix jello with hot water and sugar. Allow to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            title  \\\n",
       "0             No-Bake Nut Cookies   \n",
       "1           Jewell Ball'S Chicken   \n",
       "2                     Creamy Corn   \n",
       "3                   Chicken Funny   \n",
       "4            Reeses Cups(Candy)     \n",
       "..                            ...   \n",
       "995                 Heath Bar Pie   \n",
       "996  Victorian Baked French Toast   \n",
       "997       Quick Swedish Meatballs   \n",
       "998       Irish Stew(Microwave)     \n",
       "999                   Peach Salad   \n",
       "\n",
       "                                            directions  \n",
       "0    [In a heavy 2-quart saucepan, mix brown sugar,...  \n",
       "1    [Place chipped beef on bottom of baking dish.,...  \n",
       "2    [In a slow cooker, combine all ingredients. Co...  \n",
       "3    [Boil and debone chicken., Put bite size piece...  \n",
       "4    [Combine first four ingredients and press in 1...  \n",
       "..                                                 ...  \n",
       "995  [Mix chopped Heath bars with whipped topping a...  \n",
       "996  [Cook brown sugar, butter and corn syrup in sm...  \n",
       "997  [Combine meat, bread crumbs, cheese, soup mix,...  \n",
       "998  [In 4-quart casserole, combine lamb, 1 1/4 cup...  \n",
       "999  [Mix jello with hot water and sugar. Allow to ...  \n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset from https://recipenlg.cs.put.poznan.pl/\n",
    "import pandas as pd\n",
    "import duckdb as sql\n",
    "data = sql.query(f\"\"\"\n",
    "  select title, directions\n",
    "  from read_csv(\n",
    "    '{here('data/recipeNLG/recipeNLG.csv')}', \n",
    "    header=True,\n",
    "    delim=',',\n",
    "    types = {{\n",
    "      'title': 'VARCHAR',\n",
    "      'ingredients': 'VARCHAR[]',\n",
    "      \"directions\": 'VARCHAR[]'\n",
    "    }}\n",
    "  )\n",
    "  limit 1000\n",
    "\"\"\")\n",
    "data = data.df()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c6fba3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da51d969612b42c1b2e426bf4b082503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Formatting directions:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95ba56440ae64b598ad5c28700bd0b12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Formatting directions:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>directions</th>\n",
       "      <th>formatted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No-Bake Nut Cookies</td>\n",
       "      <td>1 - In a heavy 2-quart saucepan, mix brown sug...</td>\n",
       "      <td>Recipe: No-Bake Nut Cookies\\n\\nInstructions:\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jewell Ball'S Chicken</td>\n",
       "      <td>1 - Place chipped beef on bottom of baking dis...</td>\n",
       "      <td>Recipe: Jewell Ball'S Chicken\\n\\nInstructions:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Creamy Corn</td>\n",
       "      <td>1 - In a slow cooker, combine all ingredients....</td>\n",
       "      <td>Recipe: Creamy Corn\\n\\nInstructions:\\n1 - In a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chicken Funny</td>\n",
       "      <td>1 - Boil and debone chicken.\\n2 - Put bite siz...</td>\n",
       "      <td>Recipe: Chicken Funny\\n\\nInstructions:\\n1 - Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reeses Cups(Candy)</td>\n",
       "      <td>1 - Combine first four ingredients and press i...</td>\n",
       "      <td>Recipe: Reeses Cups(Candy)  \\n\\nInstructions:\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Heath Bar Pie</td>\n",
       "      <td>1 - Mix chopped Heath bars with whipped toppin...</td>\n",
       "      <td>Recipe: Heath Bar Pie\\n\\nInstructions:\\n1 - Mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Victorian Baked French Toast</td>\n",
       "      <td>1 - Cook brown sugar, butter and corn syrup in...</td>\n",
       "      <td>Recipe: Victorian Baked French Toast\\n\\nInstru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Quick Swedish Meatballs</td>\n",
       "      <td>1 - Combine meat, bread crumbs, cheese, soup m...</td>\n",
       "      <td>Recipe: Quick Swedish Meatballs\\n\\nInstruction...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Irish Stew(Microwave)</td>\n",
       "      <td>1 - In 4-quart casserole, combine lamb, 1 1/4 ...</td>\n",
       "      <td>Recipe: Irish Stew(Microwave)  \\n\\nInstruction...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Peach Salad</td>\n",
       "      <td>1 - Mix jello with hot water and sugar. Allow ...</td>\n",
       "      <td>Recipe: Peach Salad\\n\\nInstructions:\\n1 - Mix ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            title  \\\n",
       "0             No-Bake Nut Cookies   \n",
       "1           Jewell Ball'S Chicken   \n",
       "2                     Creamy Corn   \n",
       "3                   Chicken Funny   \n",
       "4            Reeses Cups(Candy)     \n",
       "..                            ...   \n",
       "995                 Heath Bar Pie   \n",
       "996  Victorian Baked French Toast   \n",
       "997       Quick Swedish Meatballs   \n",
       "998       Irish Stew(Microwave)     \n",
       "999                   Peach Salad   \n",
       "\n",
       "                                            directions  \\\n",
       "0    1 - In a heavy 2-quart saucepan, mix brown sug...   \n",
       "1    1 - Place chipped beef on bottom of baking dis...   \n",
       "2    1 - In a slow cooker, combine all ingredients....   \n",
       "3    1 - Boil and debone chicken.\\n2 - Put bite siz...   \n",
       "4    1 - Combine first four ingredients and press i...   \n",
       "..                                                 ...   \n",
       "995  1 - Mix chopped Heath bars with whipped toppin...   \n",
       "996  1 - Cook brown sugar, butter and corn syrup in...   \n",
       "997  1 - Combine meat, bread crumbs, cheese, soup m...   \n",
       "998  1 - In 4-quart casserole, combine lamb, 1 1/4 ...   \n",
       "999  1 - Mix jello with hot water and sugar. Allow ...   \n",
       "\n",
       "                                             formatted  \n",
       "0    Recipe: No-Bake Nut Cookies\\n\\nInstructions:\\n...  \n",
       "1    Recipe: Jewell Ball'S Chicken\\n\\nInstructions:...  \n",
       "2    Recipe: Creamy Corn\\n\\nInstructions:\\n1 - In a...  \n",
       "3    Recipe: Chicken Funny\\n\\nInstructions:\\n1 - Bo...  \n",
       "4    Recipe: Reeses Cups(Candy)  \\n\\nInstructions:\\...  \n",
       "..                                                 ...  \n",
       "995  Recipe: Heath Bar Pie\\n\\nInstructions:\\n1 - Mi...  \n",
       "996  Recipe: Victorian Baked French Toast\\n\\nInstru...  \n",
       "997  Recipe: Quick Swedish Meatballs\\n\\nInstruction...  \n",
       "998  Recipe: Irish Stew(Microwave)  \\n\\nInstruction...  \n",
       "999  Recipe: Peach Salad\\n\\nInstructions:\\n1 - Mix ...  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "tqdm.pandas(desc=\"Formatting directions\")\n",
    "\n",
    "# in directions, transform list to string, with every line starting with \"1 -\"\n",
    "data['directions'] = data['directions'].progress_apply(\n",
    "  lambda x: '\\n'.join([f\"{i+1} - {step}\" for i, step in enumerate(x)])\n",
    ")\n",
    "# format to single string, with format f\"Recipe: {title}\\n\\nInstructions:\\n{directions}\\n<|endoftext|>\"\n",
    "data['formatted'] = data.progress_apply(\n",
    "  lambda row: f\"Recipe: {row['title']}\\n\\nInstructions:\\n{row['directions']}\\n<|endoftext|>\",\n",
    "  axis=1\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "712dfaf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipe: No-Bake Nut Cookies\n",
      "\n",
      "Instructions:\n",
      "1 - In a heavy 2-quart saucepan, mix brown sugar, nuts, evaporated milk and butter or margarine.\n",
      "2 - Stir over medium heat until mixture bubbles all over top.\n",
      "3 - Boil and stir 5 minutes more. Take off heat.\n",
      "4 - Stir in vanilla and cereal; mix well.\n",
      "5 - Using 2 teaspoons, drop and shape into 30 clusters on wax paper.\n",
      "6 - Let stand until firm, about 30 minutes.\n",
      "<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(data[\"formatted\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd0478a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "# Custom Dataset class\n",
    "class RecipeDataset(Dataset):\n",
    "  def __init__(self, texts, tokenizer, max_length=512):\n",
    "    self.texts = texts\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_length = max_length\n",
    "      \n",
    "  def __len__(self):\n",
    "    return len(self.texts)\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    text = self.texts[idx]\n",
    "    encoding = self.tokenizer(\n",
    "      text,\n",
    "      truncation=True,\n",
    "      padding='max_length',\n",
    "      max_length=self.max_length,\n",
    "      return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "      'input_ids': encoding['input_ids'].flatten(),\n",
    "      'attention_mask': encoding['attention_mask'].flatten()\n",
    "    }\n",
    "\n",
    "dataset = RecipeDataset(\n",
    "  texts=data['formatted'].tolist(),\n",
    "  tokenizer=tokenizer,\n",
    "  max_length=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92505d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Plancha\\AppData\\Local\\Temp\\ipykernel_30776\\828739492.py:14: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer initialized\n",
      "Number of trainable parameters: 124,440,576\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "  output_dir=str(here('models/gpt2-recipe-finetuned')),\n",
    "  overwrite_output_dir=True,\n",
    "  num_train_epochs=3,\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "  tokenizer=tokenizer,\n",
    "  mlm=False,  # GPT-2 is not a masked language model\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "  model=model,\n",
    "  args=training_args,\n",
    "  train_dataset=dataset,\n",
    "  data_collator=data_collator,\n",
    "  tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "print(\"Trainer initialized\")\n",
    "print(f\"Number of trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7cabda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fine-tuning...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  9/375 00:30 < 26:48, 0.23 it/s, Epoch 0.06/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Start fine-tuning\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStarting fine-tuning...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Save the fine-tuned model\u001b[39;00m\n\u001b[32m      6\u001b[39m model_save_path = here(\u001b[33m'\u001b[39m\u001b[33mmodels/gpt2-recipe-finetuned\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Plancha\\Desktop\\AML-homework\\.pixi\\envs\\gpu\\Lib\\site-packages\\transformers\\trainer.py:2240\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2238\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2239\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2240\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2241\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2242\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2243\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2244\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2245\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Plancha\\Desktop\\AML-homework\\.pixi\\envs\\gpu\\Lib\\site-packages\\transformers\\trainer.py:2560\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2554\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m   2555\u001b[39m     tr_loss_step = \u001b[38;5;28mself\u001b[39m.training_step(model, inputs, num_items_in_batch)\n\u001b[32m   2557\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2558\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2559\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m-> \u001b[39m\u001b[32m2560\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   2561\u001b[39m ):\n\u001b[32m   2562\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2563\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n\u001b[32m   2564\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Start fine-tuning\n",
    "print(\"Starting fine-tuning...\")\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model_save_path = here('models/gpt2-recipe-finetuned')\n",
    "trainer.save_model(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "\n",
    "print(f\"Fine-tuned model saved to: {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a73559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing fine-tuned model:\n",
      "==================================================\n",
      "\n",
      "Recipe: Chocolate Chip Cookies\n",
      "------------------------------\n",
      "Recipe: Chocolate Chip Cookies\n",
      "\n",
      "Instructions:\n",
      "Spread peanut butter in a greased cookie sheet.\\nChill until set, about 5 minutes.\\nStir in sugar; beat 2 minutes.\\nPour chocolate chips on top.\\nMix remaining ingredients into a greased 9 x 13-inch loaf pan.\\nPour into greased 9 x 13-inch pan. Bake in 350u00b0 oven for 45 minutes.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Recipe: Beef Stew\n",
      "------------------------------\n",
      "Recipe: Chocolate Chip Cookies\n",
      "\n",
      "Instructions:\n",
      "Spread peanut butter in a greased cookie sheet.\\nChill until set, about 5 minutes.\\nStir in sugar; beat 2 minutes.\\nPour chocolate chips on top.\\nMix remaining ingredients into a greased 9 x 13-inch loaf pan.\\nPour into greased 9 x 13-inch pan. Bake in 350u00b0 oven for 45 minutes.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Recipe: Beef Stew\n",
      "------------------------------\n",
      "Recipe: Beef Stew\n",
      "\n",
      "Instructions:\n",
      "Combine all ingredients before making stew.\\nMix well.\\nAdd chicken in broth.\\nAdd onion and carrots; stir well.\\nAdd beef, rice, beans and stew mixture.\\nServes 7.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Recipe: Vegetable Soup\n",
      "------------------------------\n",
      "Recipe: Beef Stew\n",
      "\n",
      "Instructions:\n",
      "Combine all ingredients before making stew.\\nMix well.\\nAdd chicken in broth.\\nAdd onion and carrots; stir well.\\nAdd beef, rice, beans and stew mixture.\\nServes 7.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Recipe: Vegetable Soup\n",
      "------------------------------\n",
      "Recipe: Vegetable Soup\n",
      "\n",
      "Instructions:\n",
      "Mix well.\\nPreheat oven to 425u00b0.\\nIn large mixing bowl, combine the vegetable stock, onion and garlic.\\nMix well.\\nFold in the green chillies.\\nLet stand in the refrigerator overnight.\\nLet cool.\\nRefrigerate on countertop in refrigerator.\\nStore in an airtight container in a cool place.\\nBake in an 8-inch layer of grated paraffin.\\nInvert on broiler to brown.\\nBake for 1 hour at 425u00b0.\\nLet cool.\\nServes 8.\n",
      "\n",
      "==================================================\n",
      "Recipe: Vegetable Soup\n",
      "\n",
      "Instructions:\n",
      "Mix well.\\nPreheat oven to 425u00b0.\\nIn large mixing bowl, combine the vegetable stock, onion and garlic.\\nMix well.\\nFold in the green chillies.\\nLet stand in the refrigerator overnight.\\nLet cool.\\nRefrigerate on countertop in refrigerator.\\nStore in an airtight container in a cool place.\\nBake in an 8-inch layer of grated paraffin.\\nInvert on broiler to brown.\\nBake for 1 hour at 425u00b0.\\nLet cool.\\nServes 8.\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Test the fine-tuned model\n",
    "def generate_recipe(prompt, max_length=200, temperature=0.8, do_sample=True):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            max_length=max_length,\n",
    "            temperature=temperature,\n",
    "            do_sample=do_sample,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            num_return_sequences=1\n",
    "        )\n",
    "    \n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n",
    "# Test with different prompts\n",
    "test_prompts = [\n",
    "    \"Recipe: Chocolate Chip Cookies\",\n",
    "    \"Recipe: Beef Stew\",\n",
    "    \"Recipe: Vegetable Soup\"\n",
    "]\n",
    "\n",
    "print(\"Testing fine-tuned model:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for prompt in test_prompts:\n",
    "    print(f\"\\n{prompt}\")\n",
    "    print(\"-\" * 30)\n",
    "    generated = generate_recipe(prompt)\n",
    "    print(generated)\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8d239c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison with original model:\n",
      "==================================================\n",
      "Prompt: Recipe: Chocolate Chip Cookies\n",
      "\n",
      "FINE-TUNED MODEL:\n",
      "Prompt: Recipe: Chocolate Chip Cookies\n",
      "\n",
      "FINE-TUNED MODEL:\n",
      "Recipe: Chocolate Chip Cookies\n",
      "\n",
      "Instructions:\n",
      "Cut the butter in half.\\nMix the chocolate chips and graham crackers together.\\nAdd the soda, water, syrup and flour.\\nMix well.\\nAdd the chopped marshmallows.\n",
      "\n",
      "\n",
      "ORIGINAL MODEL:\n",
      "Recipe: Chocolate Chip Cookies\n",
      "\n",
      "Instructions:\n",
      "Cut the butter in half.\\nMix the chocolate chips and graham crackers together.\\nAdd the soda, water, syrup and flour.\\nMix well.\\nAdd the chopped marshmallows.\n",
      "\n",
      "\n",
      "ORIGINAL MODEL:\n",
      "Recipe: Chocolate Chip Cookies Recipe Print Ingredients 2 1/2 cups flour\n",
      "\n",
      "2 cups sugar\n",
      "\n",
      "1/2 cup granulated sugar\n",
      "\n",
      "1/4 teaspoon baking powder\n",
      "\n",
      "1/2 tsp baking soda Instructions Preheat the oven to 325 degrees. (I used a 350 degree oven) In a large mixing bowl, blend the flour, sugar, sugar, baking powder and baking soda until crumbly. Add the flour mixture to the bowl and mix with a spoon until smooth. Pour the batter into a 9-inch square baking dish. Bake for 8-10 minutes, or until a toothpick inserted comes out clean. Remove from the oven and allow the cakes to cool completely, about 8 minutes at room temperature, and then cool completely. Place the frosting on the parchment paper or foil, and press firmly with a wooden spoon. Bake for 20-25 minutes in the baking dish, or until a toothpick inserted comes out clean. Remove from the oven and allow to\n",
      "Recipe: Chocolate Chip Cookies Recipe Print Ingredients 2 1/2 cups flour\n",
      "\n",
      "2 cups sugar\n",
      "\n",
      "1/2 cup granulated sugar\n",
      "\n",
      "1/4 teaspoon baking powder\n",
      "\n",
      "1/2 tsp baking soda Instructions Preheat the oven to 325 degrees. (I used a 350 degree oven) In a large mixing bowl, blend the flour, sugar, sugar, baking powder and baking soda until crumbly. Add the flour mixture to the bowl and mix with a spoon until smooth. Pour the batter into a 9-inch square baking dish. Bake for 8-10 minutes, or until a toothpick inserted comes out clean. Remove from the oven and allow the cakes to cool completely, about 8 minutes at room temperature, and then cool completely. Place the frosting on the parchment paper or foil, and press firmly with a wooden spoon. Bake for 20-25 minutes in the baking dish, or until a toothpick inserted comes out clean. Remove from the oven and allow to\n"
     ]
    }
   ],
   "source": [
    "# Compare with original model (optional)\n",
    "print(\"Comparison with original model:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Load original model for comparison\n",
    "original_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "original_model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "def generate_with_original(prompt, max_length=200, temperature=0.8):\n",
    "    original_model.eval()\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = original_model.generate(\n",
    "            inputs.input_ids,\n",
    "            max_length=max_length,\n",
    "            temperature=temperature,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            num_return_sequences=1\n",
    "        )\n",
    "    \n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n",
    "# Compare on one example\n",
    "test_prompt = \"Recipe: Chocolate Chip Cookies\"\n",
    "print(f\"Prompt: {test_prompt}\\n\")\n",
    "\n",
    "print(\"FINE-TUNED MODEL:\")\n",
    "print(generate_recipe(test_prompt))\n",
    "print(\"\\nORIGINAL MODEL:\")\n",
    "print(generate_with_original(test_prompt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
